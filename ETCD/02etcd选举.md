高可用
===
etcd 是基于 raft算法的分布式键值数据库，生来就为集群化而设计的，由于Raft算法在做决策时需要超半数节点的投票，所以etcd集群一般推荐奇数节点，如3、5或者7个节点构成一个集群。

以上是etcd集群部署的基础概念，但是还需要注意以下问题：

选主过程
---
etcd 是高可用的，允许部分机器故障，以标准的3 节点etcd 集群，最大容忍1台机器宕机，下面以最简单的leader宕机来演示raft 的投票逻辑，以实际的运行日志来验证并理解。更多的场景可以看之前的原理解析

场景：正常运行的三台etcd：100、101、102。当前任期为 7，leader 为 101机器。现在使101 宕机

宕机前：101 为 leader，3 个 member
```
etcdctl --write-out=table --endpoints=$ENDPOINTS endpoint status
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+--------+
|     ENDPOINT      |        ID        | VERSION | DB SIZE  | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+--------+
| 10.240.0.101:2379 | 4917a7ab173fabe7 | 3.4.3   | 3.5 MB   |      true |     false  |         7 |    4340153 |            4340153 |        |
| 10.240.0.102:2379 | 59796ba9cd1bcd72 | 3.4.3   | 3.5 MB   |     false |     false  |         7 |    4340153 |            4340153 |        |
| 10.240.0.103:2379 | 94df724b66343e6c | 3.4.3   | 3.5 MB   |     false |     false  |         7 |    4340153 |            4340153 |        |
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+--------+
```

宕机后：102 成为新 leader，2 个 member
```
etcdctl --write-out=table --endpoints=$ENDPOINTS endpoint status
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+--------+
|     ENDPOINT      |        ID        | VERSION | DB SIZE  | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+--------+
| 10.240.0.102:2379 | 59796ba9cd1bcd72 | 3.4.3   | 3.5 MB   |      true |     false  |         8 |    4340153 |            4340153 |        |
| 10.240.0.103:2379 | 94df724b66343e6c | 3.4.3   | 3.5 MB   |     false |     false  |         8 |    4340153 |            4340153 |        |
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+--------+
```


过程：

将 101 机器的 etcd 停止，此时只剩 2 台，但总数为 3
- 101停止etcd 的运行
- 102(91d63231b87fadda) 收到消息，发现101(8a4bb0af2f19bd46)心跳超时，于是发起了新一轮选举，任期为 7+1=8
```
91d63231b87fadda [term 7] received MsgTimeoutNow from 8a4bb0af2f19bd46 and starts an election to get leadership.
```

- 102(91d63231b87fadda)成为新一任的候选人，然后自己投给了自己，获得 1 票
```
91d63231b87fadda became candidate at term 8
91d63231b87fadda received MsgVoteResp from 91d63231b87fadda at term 8
```

- 102(91d63231b87fadda)发送给 挂掉的101 和 另一个100，希望他们也投给自己
```
91d63231b87fadda [logterm: 7, index: 4340153] sent MsgVote request to 8a4bb0af2f19bd46 at term 8
91d63231b87fadda [logterm: 7, index: 4340153] sent MsgVote request to 9feab580a25dd270 at term 8
```

- 102 肯定收不到 101 的回应，因为 101 已经挂掉
```
etcd[24203]: lost the TCP streaming connection with peer 8a4bb0af2f19bd46 (stream MsgApp v2 reader)
```

- 100 (9feab580a25dd270)收到了 102 的拉票消息，因为任期 8 大于当前100机器所处的 7，于是知道是发起了新的一轮选举，因此回应 101，我给你投票。这里任期term是关键，也就是说，100 和 102 谁先感受到 101 宕机，发起投票，谁就是新的 leader，这个也和进程初始的启动时间有关。
```
9feab580a25dd270 [term: 7] received a MsgVote message with higher term from 91d63231b87fadda [term: 8]
9feab580a25dd270 became follower at term 8
9feab580a25dd270 [logterm: 7, index: 4340153, vote: 0] cast MsgVote for 91d63231b8
9feab580a25dd270 elected leader 91d63231b87fadda at term 8
```

- 102 获得了 2 票，一票是自己，一票是 100，超过半数，成为新的 leader。任期为 8
```
91d63231b87fadda elected leader 91d63231b87fadda at term 8
```

必须是奇数节点吗
---
etcd官方推荐3、5、7个节点，虽然raft算法也是半数以上投票才能有 leader，但奇数只是推荐，其实偶数也是可以的。如 2、4、8个节点。分情况说明：

- 1 个节点：就是单实例，没有集群概念，不做讨论
- 2 个节点：是集群，但没人会这么配，这里说点废话：双节点的etcd能启动，启动时也能有主，可以正常提供服务，但是一台挂掉之后，就选不出主了，因为他只能拿到1票，剩下的那台也无法提供服务，也就是双节点无容错能力，不要使用。

2节点正常运行：
```
etcdctl --write-out=table --endpoints=$ENDPOINTS endpoint status
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+--------+
|     ENDPOINT      |        ID        | VERSION | DB SIZE  | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+--------+
| 10.240.0.101:2379 | 4917a7ab173fabe7 | 3.4.3   |    20 kB |      true |     false  |        44 |         10 |                 10 |        |
| 10.240.0.102:2379 | 59796ba9cd1bcd72 | 3.4.3   |    20 kB |     false |     false  |        44 |         10 |                 10 |        |
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+--------+
```

1台宕机后：
```
etcdctl --write-out=table --endpoints=$ENDPOINTS endpoint status
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+-----------------------------+
|     ENDPOINT      |        ID        | VERSION | DB SIZE  | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX |                      ERRORS |
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+-----------------------------+
| 10.240.0.102:2379 | 59796ba9cd1bcd72 | 3.4.3   |    20 kB |     false |     false  |        45 |         11 |                 11 | etcdserver: no leader       |
+-------------------+------------------+---------+----------+-----------+------------+-----------+------------+--------------------+-----------------------------+
```
- 3 节点：标准的3 节点etcd 集群只能容忍1台机器宕机，挂掉 1 台的逻辑上边已经演示过，如果再挂 1 台，就和 2节点的情形一致了，一直选，一直增加任期，但就是选不出来，服务也就不可用了
- 4 节点：最大容忍1 台
- 5 节点：最大容忍 2 台
- 6 节点：最大容忍 2 台

| Cluster Size | Majority | Failure Tolerance |
|--------------|----------|-------------------|
| 1 | 1 | 0 |
| 2 | 2 | 0 |
| 3 | 2 | 1 |
| 4 | 3 | 1 |
| 5 | 3 | 2 |
| 6 | 4 | 2 |
| 7 | 4 | 3 |
| 8 | 5 | 3 |
| 9 | 5 | 4 |

你会发现偶数节点虽然多了一台机器，但是容错能力是一样的，也就是说，你可以设置偶数节点，但没增加什么能力，还浪费了一台机器。同时etcd 是通过复制数据给所有节点来达到一致性，因此偶数的多一台机器增加不了性能，反而会拉低写入速度。

机器越多越好吗
---
etcd 集群是一个 Raft Group，没有 shared。所以它的极限有两部分，一是单机的容量限制，内存和磁盘；二是网络开销，每次 Raft 操作需要所有节点参与，每一次写操作需要集群中大多数节点将日志落盘成功后，Leader 节点才能修改内部状态机，并将结果返回给客户端。因此节点越多性能越低，所以扩展很多 etcd 节点是没有意义的，一般是 3、5、7， 7 个也足够了。

在 k8s 中一般是3*master机器做高可用，也就是 3节点的 etcd。也有人将 etcd独立于 k8s集群之外，来更好地扩展 etcd 集群，或者根据 k8s 的资源来拆分 etcd，如 events 放在单独的 etcd 集群中。不同的副本数视业务规模而定，3，5，7 都可以。

脑裂问题
---
集群化的软件总会提到脑裂问题，如ElasticSearch、Zookeeper集群，脑裂就是同一个集群中的不同节点，对于集群的状态有了不一样的理解。

etcd 中有没有脑裂问题？答案是： 没有

```
The majority side becomes the available cluster and the minority side is unavailable; there is no “split-brain” in etcd.
```

以网络分区导致脑裂为例，一开始有5个节点, Node 5 为 Leader
```
  etcd1        etcd2       etcd4
  
      etcd3         etcd5-leader
```

由于出现网络故障，124 成为一个分区，35 成为一个分区， Node 5 的 leader 任期还没结束的一段时间内，仍然认为自己是当前leader，但是此时另外一边的分区，因为124无法连接 5，于是选出了新的leader 1，网络分区形成。
```
  etcd1-leader     etcd2       etcd4
  ------------------------------
      etcd3             etcd5-leader
```

35分区是否可用？如果写入了1而读取了 5，是否会读取旧数据(stale read)?

答：35分区属于少数派，被认为是异常节点，无法执行写操作。写入 1 的可以成功，并在网络分区恢复后，35 因为任期旧，会自动成为 follower，异常期间的新数据也会从 1 同步给 35。

而 5 的读请求也会失败，etcd 通过ReadIndex、Lease read保证线性一致读，即节点5在处理读请求时，首先需要与集群多数节点确认自己依然是Leader并查询 commit index，5做不到多数节点确认，因此读失败。

因此 etcd 不存在脑裂问题。线性一致读的内容下面会提到。
