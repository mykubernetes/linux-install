# PG介绍

PG, Placement Groups。CRUSH先将数据分解成一组对象，然后根据对象名称、复制级别和系统中的PG数等信息执行散列操作，再将结果生成PG ID。可以将PG看做一个逻辑容器，这个容器包含多个对象，同时这个逻辑对象映射之多个OSD上。
如果没有PG，在成千上万个OSD上管理和跟踪数百万计的对象的复制和传播是相当困难的。没有PG这一层，管理海量的对象所消耗的计算资源也是不可想象的。建议每个OSD上配置50~100个PG。
计算PG数

官方推荐如下：
- Less than 5 OSDs set pg_num to 128
- Between 5 and 10 OSDs set pg_num to 512
- Between 10 and 50 OSDs set pg_num to 1024
- If you have more than 50 OSDs, you need to understand the tradeoffs and how to calculate the pu_num value by yourself
- For calculation pg_num value by yourseif please take help of pgcalc tool

Ceph集群中的PG总数：
```
PG总数 = (OSD总数 * 100) / 最大副本数
结果必须舍入到最接近的2的N次方幂的值。

Ceph集群中每个pool中的PG总数：
存储池PG总数 = (OSD总数 * 100 / 最大副本数) / 池数
```
平衡每个存储池中的PG数和每个OSD中的PG数对于降低OSD的方差、避免速度缓慢的恢复再平衡进程是相当重要的。

# 修改PG和PGP

PGP是为了实现定位而设置的PG，它的值应该和PG的总数(即pg_num)保持一致。对于Ceph的一个pool而言，如果增加pg_num，还应该调整pgp_num为同样的值，这样集群才可以开始再平衡。
参数pg_num定义了PG的数量，PG映射至OSD。当任意pool的PG数增加时，PG依然保持和源OSD的映射。直至目前，Ceph还未开始再平衡。此时，增加pgp_num的值，PG才开始从源OSD迁移至其他的OSD，正式开始再平衡。PGP，Placement Groups of Placement。

获取现有的PG数和PGP数值：
```
ceph osd pool get data pg_num

ceph osd pool get data pgp_num
```

检查存储池的副本数
```
ceph osd dump|grep -i size
```

计算pg_num和pgp_num
```
# pg_num calculation
pg_num = (num_osds * 100) / num_copies
num_up = pow(2, int(log(pg_num,2) + 0.5))
num_down = pow(2, int(log(pg_num,2)))
if abs(pg_num - num_up) <= abs(pg_num - num_down):
    pg_num = num_up
else:
    pg_num = num_down
pgp_num = pg_num
```

修改存储池的PG和PGP
```
ceph osd pool set data pg_num 

ceph osd pool set data pgp_num
```
例子：
```
ceph osd pool ls
ceph osd pool set .rgw.root pg_num 16
ceph osd pool set .rgw.root pgp_num 16
```

# 统计pg个数

采用如下脚本统计每个pool的PG个数：
```
# ceph osd pool ls
.rgw.root
default.rgw.control
default.rgw.data.root
default.rgw.gc
default.rgw.log
default.rgw.users.uid
default.rgw.users.keys
default.rgw.usage
default.rgw.buckets.index
default.rgw.buckets.non-ec
default.rgw.buckets.data

# ceph osd pool ls | while read line; do ceph pg ls-by-pool $line | awk -v pool=$line 'BEGIN{col=0} /^[0-9a-f]+\.[0-9a-f]+/ {cols++} END{printf "%-32s: %d\n", pool, cols}'; done
.rgw.root                       : 8
default.rgw.control             : 8
default.rgw.data.root           : 8
default.rgw.gc                  : 8
default.rgw.log                 : 8
default.rgw.users.uid           : 8
default.rgw.users.keys          : 8
default.rgw.usage               : 8
default.rgw.buckets.index       : 8
default.rgw.buckets.non-ec      : 8
default.rgw.buckets.data        : 8

# ceph osd pool get default.rgw.buckets.data pgp_num
pgp_num: 8
```


# pg相关操作
```
ceph pg dump <===> ceph pg ls 查看pg组的映射关系


# 查看一个pg的map映射
ceph pg map 2.06

# 查看pg的状态
ceph pg stat


# 查看一个pg的详细信息，用下列命令：ceph pg {poolnum}.{pg-id} query
ceph pg 2.06 query 

# 洗刷一个pg组
ceph pg scrub {pg-id}

# 为找出卡住的归置组，执行：
ceph pg dump_stuck [unclean|inactive|stale|undersized|degraded]
ceph pg dump_stuck unclean  查看pg中的各种pg状态
ceph pg dump_stuck inactive
ceph pg dump_stuck stable 
ceph pg dump --format plain (纯文本)显示一个集群中所有的pg统计
             --format json  (json格式)

# 设置mon的日志等级
ceph tell mon.FOO injectargs --debug_mon 10/10

# 查看mon的配置文件信息
ceph daemon mon.FOO config show
or:
ceph daemon mon.FOO config get 'OPTION_NAME'
```

有时可能碰上osd拉起后还是有些pg不健康的，比如：
```
（1）Unfound objects
ceph集群知道该对象存在，但无法定位该object在哪时会报这个错误。
解决办法：
<1>尝试让失败的osd起来，如果起来后集群恢复正常，则结束
<2>尝试将该pg的unfound对象回滚到上一个版本，ceph pg $pgid mark_unfound_lost revert，如果恢复正常，则结束
<3>如果还是不行，那只有将该object删除掉了，注意这会导致丢失数据，ceph pg $pgid mark_unfound_lost delete

（2）inconsistent objects
pg中保存的object中有些副本数据不一致，有些事伴随着scrub errors错误
<1>ceph health detail 找出问题pg
<2>尝试ceph pg repair $pgid,若成功，则结束（这个执行修复后一般要等久点，实在不能自动repair，再用以下方式）
<3>通过ceph pg map $pgid，找出主osd，打开其日志查看是哪个object不一致
<4>找出所有该objects所有副本存放的位置，用摘要算法(md5sum,sha256)等计算出其hash值，如果是3副本，删除与其他副本不一致的；如果是2副本，则可能会误删。
<5> 再次执行 ceph pg repair $pgid

（3）stale pg
pg出现stale状态，也就是pg处于僵死状态，该状态是无法处理新的请求了的，新的请求过来只会block，这种情况一般是由于所有副本pg的osd都挂了，要模拟其实也很简单，比如设置2副本，然后将2个不同故障域的osd挂掉即可出现，最好的恢复方法当然是重新拉起这两个osd，但有时可能出现这样的情况，两个osd永远也拉不起来了，然后你把这两个osd清理出去了，清理完后这些pg当然就是stale的状态，这时的恢复方法只能是丢掉这个pg里的数据了，重新创建pg：
<1>使用命令ceph pg dump |grep stale 找出所有的stale的pg，也可以ceph health detail |grep stale
<2>执行ceph pg force_create_pg $pg_id命令强制重新创建pg，这时可以看到pg会转为creating状态
<3>重启ceph集群中的所有OSD
```
