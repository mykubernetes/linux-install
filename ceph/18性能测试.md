# 一、iperf 网络性能测试  

1、ceph的两个节点和客户端同时安装iperf  
```
# yum install iperf -y
```  

2、测试  
其中一台启动服务端（node01）
```
# iperf -s -p 6900
------------------------------------------------------------
Server listening on TCP port 6900
TCP window size: 85.3 KByte (default)
------------------------------------------------------------
```  

其他节点启动一台客户端(node03)
```
# iperf -c node01 -p 6900
------------------------------------------------------------
Client connecting to node01, TCP port 6900
TCP window size:  204 KByte (default)
------------------------------------------------------------
[  3] local 192.168.101.71 port 56116 connected with 192.168.101.69 port 6900
[ ID] Interval       Transfer     Bandwidth
[  3]  0.0-10.0 sec  2.00 GBytes  1.72 Gbits/sec
```  
注意1.72 Gbits/sec值要除以8，就是正常带宽  


# 二、Rados bench 性能测试

Ceph附带内置基准测试工具称为rados bench，可用于测量池级别的Ceph集群的性能。该rados bench工具支持写入，顺序读取和随机读取基准测试，并且还允许清理临时基准测试数据，这非常简洁。  

语法：
```
rados bench -p <pool_name> <seconds> <write|seq|rand> -b <blocksize> -t --no-cleanup  
```
- pool_name: 测试的存储池名称
- seconds: 测试时间，以秒为单位
- <write|seq|rand>：操作的模式，write:写 seq:顺序读 rand:随机读
- -b：block size即块大小，默认为4M
- -t：读/写并行数，默认为16
- --no-cleanup：表示测试完成后不删除测试用数据，在做读测试之前，需要使用该参数运行一遍写测试来产生数据，在全部测试完毕后可以运行rados -p <pool_name> cleanup 来清理数据



查看帮助  
```
# rados bench help
```

1、写入测试  
不清除数据对RDB运行10s写入测试  
```
# rados bench -p test 60 write --no-cleanup
hints = 1
Maintaining 16 concurrent writes of 4194304 bytes to objects of size 4194304 for up to 60 seconds or 0 objects
Object prefix: benchmark_data_openstack01_603
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0       0         0         0         0         0           -           0
    1      16        16         0         0         0           -           0
    2      16        16         0         0         0           -           0
    3      16        24         8   10.6653   10.6667     2.66058     2.22005
    4      16        27        11   10.9986        12     3.19831     2.45947
    5      16        29        13   10.3986         8     2.54069     2.61219
    6      16        38        22   14.6647        36     2.52673     3.23277
    7      16        43        27   15.4265        20     4.06122     3.28708
    8      16        46        30    14.998        12     3.23905     3.27569
    9      16        47        31   13.7759         4     2.94027     3.26487
   10      16        50        34   13.5982        12     3.41596     3.31326
   11      16        55        39   14.1799        20      5.3298     3.45411
   12      16        58        42   13.9981        12     5.90129     3.60335
   13      16        59        43    13.229         4     6.06364     3.66057
   14      16        61        45   12.8554         8     5.25054     3.74845
   15      16        64        48   12.7982        12     8.46896     3.84977
   16      16        65        49   12.2483         4     7.87838     3.93199
   17      16        68        52   12.2336        12     7.36673     4.06689
   18      16        72        56   12.4427        16        7.06      4.2234
   19      16        75        59   12.4193        12     7.78165     4.30382
2018-10-11 11:57:52.537579 min lat: 1.89714 max lat: 8.54175 avg lat: 4.35334
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
   20      16        79        63   12.5982        16     6.90524     4.35334
   21      16        83        67   12.7601        16     5.97492     4.47472
   22      16        85        69   12.5437         8     5.49733     4.50754
   23      16        86        70   12.1722         4      4.1921     4.50304
   24      16        87        71   11.8317         4     6.14773      4.5262
   25      16        90        74   11.8383        12     5.11989      4.5118
   26      16        91        75   11.5368         4      5.1742     4.52063
   27      16        95        79   11.7021        16     8.31085     4.62613
   28      16        96        80    11.427         4      7.6217     4.66358
   29      16        96        80   11.0329         0           -     4.66358
   30      16        96        80   10.6652         0           -     4.66358
   31      16        96        80   10.3211         0           -     4.66358
   32      16        96        80   9.99859         0           -     4.66358
   33      16        96        80   9.69558         0           -     4.66358
   34      16        96        80   9.41042         0           -     4.66358
   35      16       101        85   9.71291   2.85714      8.7633     4.95709
   36      16       101        85   9.44309         0           -     4.95709
   37      16       103        87   9.40406         4     17.9027      5.1727
   38      16       105        89   9.36708         8     18.0327     5.37878
   39      16       105        89   9.12691         0           -     5.37878
2018-10-11 11:58:12.540426 min lat: 1.89714 max lat: 18.0327 avg lat: 5.37878
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
   40      16       105        89   8.89874         0           -     5.37878
   41      16       105        89   8.68167         0           -     5.37878
   42      16       106        90   8.57019         1     6.43809     5.39055
   43      16       114        98   9.11497        32     5.11341     6.40932
   44      16       115        99   8.99871         4     7.16406     6.41694
   45      16       115        99   8.79874         0           -     6.41694
   46      16       116       100   8.69442         2     11.4983     6.46775
   47      16       118       102   8.67962         8     9.64869     6.54381
   48      16       119       103   8.58212         4     5.13036     6.53009
   49      16       119       103   8.40697         0           -     6.53009
   50      16       120       104   8.31882         2     7.10649     6.53563
   51      16       125       109   8.54781        20     8.44788     6.79488
   52      16       130       114     8.768        20     9.57393     6.83936
   53      16       134       118    8.9044        16     10.3648     6.79498
   54      16       136       120   8.88764         8     9.32118     6.81407
   55      16       140       124   9.01692        16     2.17708     6.69443
   56      16       140       124    8.8559         0           -     6.69443
   57      16       143       127   8.91103         6     4.81556     6.68976
   58      16       146       130   8.96426        12     10.3827     6.68146
   59      16       146       130   8.81232         0           -     6.68146
2018-10-11 11:58:32.543137 min lat: 1.63302 max lat: 23.564 avg lat: 6.68146
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
   60      16       146       130   8.66545         0           -     6.68146
   61      16       146       130   8.52339         0           -     6.68146
   62      16       146       130   8.38592         0           -     6.68146
   63      16       146       130   8.25281         0           -     6.68146
   64      16       146       130   8.12387         0           -     6.68146
   65      16       146       130   7.99889         0           -     6.68146
   66      16       146       130   7.87769         0           -     6.68146
   67      11       147       136   8.11828   2.66667     15.7406     6.94076
   68      11       147       136   7.99889         0           -     6.94076
   69      11       147       136   7.88297         0           -     6.94076
Total time run:         69.107454
Total writes made:      147
Write size:             4194304
Object size:            4194304
Bandwidth (MB/sec):     8.50849
Stddev Bandwidth:       7.95831
Max bandwidth (MB/sec): 36
Min bandwidth (MB/sec): 0
Average IOPS:           2
Stddev IOPS:            2
Max IOPS:               9
Min IOPS:               0
Average Latency(s):     7.44131
Stddev Latency(s):      4.9394
Max latency(s):         23.564
Min latency(s):         1.63302
```  
- 上面数据Bandwidth为8.50849MB/sec，Average Latency为：7.44131s

2、随机读取测试  
```
# rados bench -p test 60 rand
hints = 1
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0       0         0         0         0         0           -           0
    1      16       152       136   543.849       544   0.0743183   0.0995761
    2      16       306       290   579.818       616  0.00970808    0.102821
    3      16       444       428   570.514       552   0.0405567    0.104487
    4      15       568       553   552.862       500  0.00818665    0.109911
    5      16       700       684   546.952       524    0.043003    0.111776
    6      16       836       820   546.446       544    0.104833    0.113024
    7      16       959       943   538.658       492   0.0117524    0.114411
    8      16      1079      1063   531.318       480   0.0381715    0.116316
    9      16      1199      1183   525.608       480   0.0552762    0.118574
   10      16      1293      1277   510.644       376   0.0362924    0.117607
   11      16      1423      1407   511.476       520   0.0142599    0.122025
   12      16      1566      1550   516.511       572    0.008037     0.12061
   13      16      1686      1670   513.694       480  0.00940001    0.119639
   14      16      1793      1777   507.568       428   0.0111657    0.123314
   15      16      1923      1907    508.39       520   0.0120602    0.123097
   16      16      2047      2031   507.611       496   0.0106408     0.12326
   17      16      2164      2148   505.277       468  0.00817543    0.123239
   18      16      2264      2248   499.426       400   0.0130886    0.125529
   19      15      2391      2376   500.083       512  0.00987636    0.125445
2018-10-11 14:27:20.997424 min lat: 0.00644293 max lat: 1.0492 avg lat: 0.125502
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
   20      16      2516      2500   499.875       496  0.00979231    0.125502
   21      16      2642      2626   500.067       504    0.271557    0.125655
   22      16      2769      2753   500.424       508  0.00853595     0.12471
   23      16      2891      2875    499.88       488    0.358424    0.125615
   24      16      3009      2993   498.716       472    0.356571    0.125675
   25      16      3127      3111   497.645       472    0.452718    0.125959
   26      15      3269      3254     500.5       572    0.286575    0.125597
   27      16      3393      3377   500.182       492   0.0994856    0.125185
   28      16      3512      3496   499.316       476   0.0637264    0.125534
   29      16      3648      3632   500.853       544    0.307832    0.125653
   30      15      3791      3776   503.354       576  0.00929097    0.124856
   31      16      3919      3903   503.501       508  0.00955382    0.124689
   32      16      4045      4029   503.514       504    0.180285    0.124946
   33      15      4150      4135   501.103       424   0.0448866    0.125427
   34      16      4287      4271   502.361       544    0.363722    0.125243
   35      16      4394      4378   500.233       428  0.00944837    0.125241
   36      16      4512      4496   499.447       472   0.0106443       0.126
   37      16      4629      4613   498.591       468   0.0995126    0.126007
   38      16      4738      4722   496.941       436    0.267176    0.126746
   39      16      4869      4853   497.626       524    0.303769    0.126441
2018-10-11 14:27:41.001727 min lat: 0.00644293 max lat: 1.0492 avg lat: 0.126309
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
   40      16      4999      4983   498.184       520   0.0542142    0.126309
   41      16      5119      5103   497.739       480  0.00888314    0.126283
   42      15      5245      5230   497.976       508   0.0360334    0.126255
   43      16      5380      5364   498.857       536    0.015746    0.126103
   44      16      5508      5492   499.152       512     0.22606    0.126146
   45      16      5626      5610   498.547       472   0.0110425    0.126163
   46      16      5759      5743   499.273       532    0.378206    0.126063
   47      16      5885      5869   499.372       504   0.0112606    0.125814
   48      15      6000      5985   498.634       464     0.42884    0.126265
   49      16      6127      6111    498.74       504    0.611502    0.126078
   50      16      6255      6239   499.004       512    0.100672      0.1262
   51      16      6370      6354   498.238       460    0.428983     0.12635
   52      16      6495      6479   498.271       500   0.0130692    0.126363
   53      16      6620      6604   498.302       500    0.160325    0.126399
   54      16      6748      6732   498.554       512   0.0384334    0.126252
   55      16      6885      6869   499.448       548  0.00900053     0.12599
   56      15      7016      7001   499.956       528   0.0435343    0.125842
   57      15      7136      7121   499.603       480   0.0516195    0.125927
   58      16      7243      7227   498.299       424    0.224335    0.126219
   59      16      7368      7352   498.326       500   0.0679909    0.126414
2018-10-11 14:28:01.006114 min lat: 0.00644293 max lat: 1.0492 avg lat: 0.126286
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
   60      15      7502      7487   499.019       540   0.0106773    0.126286
Total time run:       60.227155
Total reads made:     7502
Read size:            4194304
Object size:          4194304
Bandwidth (MB/sec):   498.247
Average IOPS:         124
Stddev IOPS:          10
Max IOPS:             154
Min IOPS:             94
Average Latency(s):   0.126668
Max latency(s):       1.0492
Min latency(s):       0.00644293
```  
- 上面数据Bandwidth为498.247MB/sec，Average Latency为：0.126668s

3、顺序读取测试
```
# rados bench -p test 60 seq
hints = 1
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0       0         0         0         0         0           -           0
    1      16       147       131   523.861       524   0.0094258   0.0971213
Total time run:       1.199266
Total reads made:     147
Read size:            4194304
Object size:          4194304
Bandwidth (MB/sec):   490.3
Average IOPS:         122
Stddev IOPS:          0
Max IOPS:             131
Min IOPS:             131
Average Latency(s):   0.126695
Max latency(s):       0.612257
Min latency(s):       0.00736062
```
- 上面数据Bandwidth为490.3MB/sec，Average Latency为：0.126695s

4、清除测试数据  
```
# rados -p rbd cleanup
```  

# 三、Rados bench-write img 测试

- 只能对块设备做写测试

创建测试 img
```
$ rbd create test_img --size 5120
$ rbd -p rbd ls
...
test_img
```

（1）顺序读写
```
# rbd bench-write test_img --io-threads 16 --pool=rbd --io-pattern seq --io-total 171997000

rbd: bench-write is deprecated, use rbd bench --io-type write ...
bench type write io_size 4096 io_threads 16 bytes 171997000 pattern seq uential
SEC      OPS      OPS/SEC          BYTES/SEC
1       6625      4349.81        17816805.42
2       8360      4121.99        16883686.08
3      10624      3546.65        14527082.88
4      12425      3054.79        12512438.83
5      15321      3037.24        12440545.75
6      18510      2411.21        9876325.65
7      20699      2415.82        9895180.54
8      23802      2553.94        10460934.33
9      25777      2564.45        10503981.70
10     28565      2675.32        10958122.36
11     31634      2745.85        11246987.67
12     34935      2633.41        10786453.94
13     37648      2860.61        11717062.30
14     39900      2863.49        11728848.67
elapsed:   17  ops:   41992  ops/sec:   2465.13  bytes/sec: 10097188.73
```
- 测试：默认 block size 是 4k,16个并发线程
- 结果：带宽 10 M

4M 块，io总数多*10，因为时间过短，可能无法显示效果
```
# rbd bench-write test_img --io-threads 16 --pool=rbd --io-pattern seq --io-total 1719970000 --io-size 4096000

rbd: bench-write is deprecated, use rbd bench --io-type write ...
bench type write io_size 4096000 io_threads 16 bytes 1719970000 pattern
sequential
SEC     OPS       OPS/SEC       BYTES/SEC
5        13          5.58      22869949.12
...
117     403          3.41      13971880.02
125     404          2.43       9956769.69
elapsed:  127  ops:  420  ops/sec:  3.31 bytes/sec:  13542554.56
```
- 测试：block size 是 4M,16个并发线程
- 结果：带宽 13 M

（2）随机读写
```
# rbd bench-write test_img --io-threads 16 --pool=rbd --io-pattern rand --io-total 171997

rbd: bench-write is deprecated, use rbd bench --io-type write ...
bench type write io_size 4096 io_threads 16 bytes 171997 pattern random
SEC       OPS        OPS/SEC         BYTES/SEC
28          8           0.84            3439.89
elapsed:  29   ops:  42   ops/sec:  1.41   bytes/sec:   5779.41
```
- 测试：block size 是 4k,16个并发线程
- 结果：带宽 5 k

```
# rbd bench-write test_img --io-threads 16 --pool=rbd --io-pattern rand --io-total 171997000 --io-size 4096000
rbd: bench-write is deprecated, use rbd bench --io-type write ...
bench type write io_size 4096000 io_threads 16 bytes 171997000 pattern
random
SEC     OPS     OPS/SEC     BYTES/SEC
4        22        8.43    34547477.78
8        26        5.21    21343012.54
elapsed:  10   ops:  42  ops/sec:  4.19  bytes/sec:  17160587.03
```
- 测试：block size 是 4M,16个并发线程
- 结果：带宽 17M

# 四、云硬盘性能测试工具FIO介绍 

### 1、云硬盘性能衡量指标

云硬盘的性能指标一般通过以下几个指标进行衡量

- IOPS：每秒的读写次数，单位为次（计数）。存储设备的底层驱动类型决定了不同的IOPS
  - 总IOPS：每秒执行的I/O操作总次数
  - 随机读IOPS：每秒指定的随机读I/O操作的平均次数
  - 随机写IOPS 每秒指定的随机写I/O操作的平均次数
  - 顺序读IOPS 每秒指定的顺序读I/O操作的平均次数
  - 顺序写IOPS 每秒指定的顺序写I/O操作的平均次数
- 吞吐量：每秒的读写数据量，单位为MB/S
  - 吞吐量市值单位时间内可以成功传输的数据数量。
  - 如果需要部署大量顺序读写的应用，典型场景比如hadoop离线计算型业务，需要关注吞吐量
- 时延：IO操作的发送时间到接收确认所经过的时间，单位为秒
  - 如果应用对时延比较敏感，比如数据库（过高时延会导致应用性能下降或报错），建议使用SSD存储

### 2、具体参数说明
```
# fio --bs=4k --ioengine=libaio --iodepth=1 --direct=1 --rw=read --time_based --runtime=600  --refill_buffers --norandommap --randrepeat=0 --group_reporting --name=fio-read --size=100G --filename=/dev/vdb 

fio-read: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1
fio-3.1
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=9784KiB/s,w=0KiB/s][r=2446,w=0 IOPS][eta 00m:00s]
fio-read: (groupid=0, jobs=1): err= 0: pid=22004: Wed Oct 10 21:35:42 2018
   read: IOPS=2593, BW=10.1MiB/s (10.6MB/s)(6078MiB/600001msec)
    slat (usec): min=4, max=1532, avg=11.98, stdev= 8.10
    clat (nsec): min=1021, max=66079k, avg=370367.39, stdev=395393.29
     lat (usec): min=44, max=66086, avg=382.88, stdev=399.21
    clat percentiles (usec):
     |  1.00th=[   42],  5.00th=[   44], 10.00th=[   45], 20.00th=[   46],
     | 30.00th=[   48], 40.00th=[   51], 50.00th=[  383], 60.00th=[  578],
     | 70.00th=[  644], 80.00th=[  701], 90.00th=[  783], 95.00th=[  865],
     | 99.00th=[  988], 99.50th=[ 1020], 99.90th=[ 1336], 99.95th=[ 2057],
     | 99.99th=[11338]
   bw (  KiB/s): min= 2000, max=68272, per=99.98%, avg=10370.55, stdev=8123.28, samples=1199
   iops        : min=  500, max=17068, avg=2592.62, stdev=2030.82, samples=1199
  lat (usec)   : 2=0.01%, 20=0.01%, 50=37.97%, 100=10.63%, 250=0.39%
  lat (usec)   : 500=6.09%, 750=31.54%, 1000=12.65%
  lat (msec)   : 2=0.67%, 4=0.03%, 10=0.01%, 20=0.01%, 50=0.01%
  lat (msec)   : 100=0.01%
  cpu          : usr=1.43%, sys=5.12%, ctx=1555984, majf=0, minf=35
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=1556003,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=1

Run status group 0 (all jobs):
   READ: bw=10.1MiB/s (10.6MB/s), 10.1MiB/s-10.1MiB/s (10.6MB/s-10.6MB/s), io=6078MiB (6373MB), run=600001-600001msec

Disk stats (read/write):
  vdb: ios=1555778/0, merge=0/0, ticks=570518/0, in_queue=569945, util=95.04%
```

| 参数详情 | 含义 |
|---------|-----|
| io | 执行了多少M的IO |
| bw | 平均IO带宽 |
| iops | IOPS |
| runt | 线程运行时间 |
| slat | 提交延迟 |
| clat | 完成延迟 |
| lat | 响应时间 |
| cpu | cpu利用率 |
| IO depths | io队列 |
| IO submit | 单个IO提交要提交的IO数 |
| IO complete |  |
| IO issued |  |
| IO latency |  |

### 3、FIO测试工具参数说明

```
# fio -direct=1 -iodepth=64 -rw=read -ioengine=libaio -bs=4096k -size=100G -numjobs=1 -runtime=300 -group_reporting -filename=/dev/vdb -name=Write_PPS_Testing
```

注意： 测试裸盘可以获得真实的硬盘性能，但直接测试裸盘会破坏文件系统结构，请在测试前提前做好数据备份

| 参数 | 说明 |
|------|-----|
| -direct=1 | 表示测试时忽略I/O缓存，数据直写 |
| -iodepth=128 | 表示使用AIO时，同时发出I/O数的上限为128 |
| -rw=randwrite | 表示测试时的读写策略为随机写（random writes）。作其它测试时可以设置为：randread（随机读random reads）read（顺序读sequential reads） write（顺序写sequential writes）randrw（混合随机读写mixed random reads and writes） |
| -ioengine=libaio | 表示测试方式为libaio（Linux AIO，异步I/O）。应用程序使用I/O通常有两种方式： 同步：同步的I/O一次只能发出一个I/O请求，等待内核完成才返回。这样对于单个线程iodepth总是小于1，但是可以透过多个线程并发执行来解决。通常会用16−32根线程同时工作将iodepth塞满。异步：异步的I/O通常使用libaio这样的方式一次提交一批I/O请求，然后等待一批的完成，减少交互的次数，会更有效率。 |
| -bs=4k | 表示单次I/O的块文件大小为4 KB。未指定该参数时的默认大小也是4 KB，测试IOPS时，建议将bs设置为一个比较小的值，如本示例中的4k。测试吞吐量时，建议将bs设置为一个较大的值，如本示例中的1024k |
| -size=1G | 表示测试文件大小为1 GiB |
| -numjobs=1 | 表示测试线程数为1 |
| -runtime=1000 | 表示测试时间为1000秒。如果未配置，则持续将前述-size指定大小的文件，以每次-bs值为分块大小写完 |
| -group_reporting | 表示测试结果里汇总每个进程的统计信息，而非以不同job汇总展示信息 |
| -filename=iotest | 指定测试文件的名称，比如iotest。测试裸盘可以获得真实的硬盘性能，但直接测试裸盘会破坏文件系统结构，请在测试前提前做好数据备份 |
| -name=Rand_Write_Testing | 表示测试任务名称为Rand_Write_Testing，可以随意设定 |

### 4、测试结果

- 这里我们以4K的数据块测试随机读和随机写来测试最大的IOPS，4M的块测试顺序读和顺序写来测试最大的吞吐量

1)测试4K块的随机写
```
# fio --bs=4k --ioengine=libaio --iodepth=128 --direct=1 --rw=randwrite --time_based --runtime=300  --refill_buffers --norandommap --randrepeat=0 --group_reporting --name=fio-write --size=1G --filename=/dev/vdb 

fio-write: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=128
fio-3.1
Starting 1 process
Jobs: 1 (f=1): [w(1)][100.0%][r=0KiB/s,w=3996KiB/s][r=0,w=999 IOPS][eta 00m:00s]
fio-write: (groupid=0, jobs=1): err= 0: pid=22050: Wed Oct 10 22:29:32 2018
  write: IOPS=2819, BW=11.0MiB/s (11.5MB/s)(3309MiB/300484msec)
    slat (usec): min=2, max=2399, avg= 9.54, stdev=10.19
    clat (usec): min=1180, max=3604.0k, avg=45387.25, stdev=168013.09
     lat (usec): min=1201, max=3604.0k, avg=45397.35, stdev=168013.57
    clat percentiles (usec):
     |  1.00th=[   1713],  5.00th=[   2212], 10.00th=[   2835],
     | 20.00th=[   4015], 30.00th=[   5211], 40.00th=[   6849],
     | 50.00th=[   8979], 60.00th=[  11994], 70.00th=[  17695],
     | 80.00th=[  33162], 90.00th=[  61604], 95.00th=[ 137364],
     | 99.00th=[ 893387], 99.50th=[1266680], 99.90th=[2122318],
     | 99.95th=[2432697], 99.99th=[2969568]
   bw (  KiB/s): min=    8, max=49120, per=100.00%, avg=11603.11, stdev=10950.79, samples=584
   iops        : min=    2, max=12280, avg=2900.77, stdev=2737.69, samples=584
  lat (msec)   : 2=3.16%, 4=16.75%, 10=33.83%, 20=18.49%, 50=14.82%
  lat (msec)   : 100=6.56%, 250=2.86%, 500=1.49%, 750=0.70%, 1000=0.53%
  lat (msec)   : 2000=0.69%, >=2000=0.12%
  cpu          : usr=1.84%, sys=4.16%, ctx=323739, majf=0, minf=28
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwt: total=0,847133,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
  WRITE: bw=11.0MiB/s (11.5MB/s), 11.0MiB/s-11.0MiB/s (11.5MB/s-11.5MB/s), io=3309MiB (3470MB), run=300484-300484msec

Disk stats (read/write):
  vdb: ios=91/847074, merge=0/0, ticks=3/38321566, in_queue=38360706, util=100.00%
```
- 可以看到4K的数据块，随机写的最大IOPS为：12280

2)测试4K的随机读
```
# fio --bs=4k --ioengine=libaio --iodepth=128 --direct=1 --rw=randread --time_based --runtime=300  --refill_buffers --norandommap --randrepeat=0 --group_reporting --name=fio-write --size=1G --filename=/dev/vdb 

fio-write: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=128
fio-3.1
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=87.1MiB/s,w=0KiB/s][r=22.3k,w=0 IOPS][eta 00m:00s]
fio-write: (groupid=0, jobs=1): err= 0: pid=22055: Wed Oct 10 22:51:54 2018
   read: IOPS=22.3k, BW=87.0MiB/s (91.2MB/s)(25.5GiB/300004msec)
    slat (usec): min=2, max=8626, avg= 7.91, stdev=11.85
    clat (usec): min=36, max=71810, avg=5735.17, stdev=1405.20
     lat (usec): min=45, max=71826, avg=5743.59, stdev=1405.30
    clat percentiles (usec):
     |  1.00th=[ 1958],  5.00th=[ 3556], 10.00th=[ 4424], 20.00th=[ 5145],
     | 30.00th=[ 5407], 40.00th=[ 5604], 50.00th=[ 5735], 60.00th=[ 5866],
     | 70.00th=[ 6063], 80.00th=[ 6259], 90.00th=[ 6783], 95.00th=[ 7504],
     | 99.00th=[10290], 99.50th=[12256], 99.90th=[16712], 99.95th=[18482],
     | 99.99th=[25035]
   bw (  KiB/s): min=74872, max=93240, per=100.00%, avg=89121.48, stdev=2687.55, samples=600
   iops        : min=18718, max=23310, avg=22280.35, stdev=671.89, samples=600
  lat (usec)   : 50=0.01%, 100=0.01%, 250=0.01%, 500=0.02%, 750=0.06%
  lat (usec)   : 1000=0.12%
  lat (msec)   : 2=0.86%, 4=6.02%, 10=91.77%, 20=1.11%, 50=0.03%
  lat (msec)   : 100=0.01%
  cpu          : usr=6.56%, sys=28.57%, ctx=3473136, majf=0, minf=160
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwt: total=6683408,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=87.0MiB/s (91.2MB/s), 87.0MiB/s-87.0MiB/s (91.2MB/s-91.2MB/s), io=25.5GiB (27.4GB), run=300004-300004msec

Disk stats (read/write):
  vdb: ios=6680955/0, merge=0/0, ticks=37981396/0, in_queue=37983491, util=100.00%
```
- 可以看到4K的数据块，随机读的最大IOPS为：23310

3)测试4M的顺序写
```
# fio -direct=1 -iodepth=64 -rw=write -ioengine=libaio -bs=4096k -size=100G -numjobs=1 -runtime=300 -group_reporting -filename=/dev/vdb -name=Write_PPS_Testing

Write_PPS_Testing: (g=0): rw=write, bs=(R) 4096KiB-4096KiB, (W) 4096KiB-4096KiB, (T) 4096KiB-4096KiB, ioengine=libaio, iodepth=64
fio-3.1
Starting 1 process
Jobs: 1 (f=1): [W(1)][100.0%][r=0KiB/s,w=108MiB/s][r=0,w=27 IOPS][eta 00m:00s]
Write_PPS_Testing: (groupid=0, jobs=1): err= 0: pid=22098: Wed Oct 10 23:20:07 2018
  write: IOPS=28, BW=115MiB/s (120MB/s)(33.7GiB/300466msec)
    slat (usec): min=564, max=2554.1k, avg=34767.87, stdev=65067.32
    clat (msec): min=400, max=12179, avg=2188.04, stdev=1037.46
     lat (msec): min=473, max=12231, avg=2222.81, stdev=1047.45
    clat percentiles (msec):
     |  1.00th=[ 1435],  5.00th=[ 1586], 10.00th=[ 1653], 20.00th=[ 1754],
     | 30.00th=[ 1838], 40.00th=[ 1921], 50.00th=[ 2005], 60.00th=[ 2089],
     | 70.00th=[ 2198], 80.00th=[ 2333], 90.00th=[ 2534], 95.00th=[ 2802],
     | 99.00th=[ 8490], 99.50th=[ 9731], 99.90th=[11745], 99.95th=[12013],
     | 99.99th=[12147]
   bw (  KiB/s): min= 8192, max=196608, per=100.00%, avg=120954.04, stdev=31456.39, samples=580
   iops        : min=    2, max=   48, avg=29.53, stdev= 7.68, samples=580
  lat (msec)   : 500=0.02%, 750=0.03%, 1000=0.13%, 2000=49.25%, >=2000=50.56%
  cpu          : usr=1.04%, sys=2.16%, ctx=6387, majf=0, minf=29
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.2%, 32=0.4%, >=64=99.3%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwt: total=0,8627,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=115MiB/s (120MB/s), 115MiB/s-115MiB/s (120MB/s-120MB/s), io=33.7GiB (36.2GB), run=300466-300466msec

Disk stats (read/write):
  vdb: ios=91/77596, merge=0/0, ticks=6/37685137, in_queue=37717833, util=99.99%
```
- 可以看到4M的数据块，顺序写的最大吞吐量为：196M

4)测试4M的顺序读
```
# fio -direct=1 -iodepth=64 -rw=read -ioengine=libaio -bs=4096k -size=100G -numjobs=1 -runtime=300 -group_reporting -filename=/dev/vdb -name=Write_PPS_Testing

Write_PPS_Testing: (g=0): rw=read, bs=(R) 4096KiB-4096KiB, (W) 4096KiB-4096KiB, (T) 4096KiB-4096KiB, ioengine=libaio, iodepth=64
fio-3.1
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=312MiB/s,w=0KiB/s][r=78,w=0 IOPS][eta 00m:00s]
Write_PPS_Testing: (groupid=0, jobs=1): err= 0: pid=22103: Wed Oct 10 23:26:31 2018
   read: IOPS=35, BW=142MiB/s (149MB/s)(41.6GiB/300201msec)
    slat (usec): min=469, max=95190, avg=28166.40, stdev=15966.53
    clat (msec): min=185, max=4070, avg=1772.98, stdev=551.21
     lat (msec): min=205, max=4107, avg=1801.15, stdev=558.25
    clat percentiles (msec):
     |  1.00th=[  518],  5.00th=[  634], 10.00th=[  751], 20.00th=[ 1536],
     | 30.00th=[ 1770], 40.00th=[ 1854], 50.00th=[ 1921], 60.00th=[ 1989],
     | 70.00th=[ 2039], 80.00th=[ 2140], 90.00th=[ 2299], 95.00th=[ 2433],
     | 99.00th=[ 2802], 99.50th=[ 2970], 99.90th=[ 3473], 99.95th=[ 3641],
     | 99.99th=[ 3775]
   bw (  KiB/s): min=106496, max=466944, per=99.97%, avg=145216.28, stdev=60136.24, samples=597
   iops        : min=   26, max=  114, avg=35.45, stdev=14.68, samples=597
  lat (msec)   : 250=0.10%, 500=0.66%, 750=9.21%, 1000=7.02%, 2000=46.51%
  lat (msec)   : >=2000=36.51%
  cpu          : usr=0.05%, sys=2.61%, ctx=10959, majf=0, minf=672
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.2%, 32=0.3%, >=64=99.4%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwt: total=10646,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=142MiB/s (149MB/s), 142MiB/s-142MiB/s (149MB/s-149MB/s), io=41.6GiB (44.7GB), run=300201-300201msec

Disk stats (read/write):
  vdb: ios=95740/0, merge=0/0, ticks=37360788/0, in_queue=37382226, util=100.00%
```
- 可以看到4M的数据块，顺序读的最大吞吐量为：466M


### 4M块测试
（1）顺序读（block size 4M）
```
# cat rbd-4M-seq-30job.fio
[seqread-4M]
description="file 4M seqread 16job test"
filename=/mnt/cephfile/test
direct=1
iodepth=1
thread=1
rw=read
ioengine=libaio
bs=4M
size=1G
numjobs=30
runtime=120
group_reporting=1
name=read-liaio

# fio rbd-4M-seq-30job.fio
```

（2）随机读（block size 4M）
```
...
rw=randread
...
```

（3）顺序写(block size 4M)
```
...
rw=write
...
```

（4）随机写(block size 4M)
```
...
rw=randwrite
...
```

（5）顺序读写(block size 4M)
```
...
rw=rw
...
```

（6）随机读写(block size 4M)
```
...
rw=randrw
...
```

### 4k块测试

（1）顺序读（block size 4k）
```
# cat rbd-4M-seq-30job.fio
[seqread-4M]
description="file 4M seqread 16job test"
filename=/mnt/cephfile/test
direct=1
iodepth=1
thread=1
rw=read
ioengine=libaio
bs=4k
size=1G
numjobs=30
runtime=120
group_reporting=1
name=read-liaio

# fio rbd-4M-seq-30job.fio
```

（2）随机读（block size 4M）
```
...
rw=randread
...
```

（3）顺序写(block size 4M)
```
...
rw=write
...
```

（4）随机写(block size 4M)
```
...
rw=randwrite
...
```

（5）顺序读写(block size 4M)
```
...
rw=rw
...
```

（6）随机读写(block size 4M)
```
...
rw=randrw
...
```
