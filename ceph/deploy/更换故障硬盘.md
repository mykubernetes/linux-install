移除故障磁盘  
---
1、已经移除一个磁盘，查看osd状态  
```
# ceph osd tree
ID CLASS WEIGHT TYPE NAME STATUS REWEIGHT PRI-AFF
-1 0.17537 root default
-3 0.05846 host node01
 0 hdd 0.01949 osd.0 up 1.00000 1.00000
 3 hdd 0.01949 osd.3 down 1.00000 1.00000
 6 hdd 0.01949 osd.6 up 1.00000 1.00000
...
```  

2、查看集群状态  
```
# ceph status
  cluster:
    id: 15484ab5-ddb2-4a54-b9b3-ed8674bc5d05
    health: HEALTH_WARN
            1 osds down
            Degraded data redundancy: 21/186 objects degraded (11.290%),
17 pgs degraded
            application not enabled on 1 pool(s)
  services:
    mon: 3 daemons, quorum node01,node02,nonde03
    mgr: node01(active), standbys: node02,node03
    mds: cephfs-1/1/1 up {0=c720178=up:active}, 2 up:standby
    osd: 9 osds: 8 up, 9 in
...
```  
- 可能看到提示还有9个in，目前，它不会触发此驱动器的数据恢复，一般需要300s才将磁盘标记为Out ，然后触发数据恢复。此超时的原因是为了避免由于短期中断而导致的不必要的数据移动。你如果不想等待 300s，可以手工标记为 Out  

3、可以手工标记为Out  
``` ceph osd out osd.3 ```  

- 一旦OSD标记为OUT，Ceph集群将立即启动对故障磁盘上托管的PG的恢复操作。可以使用以下命令观察恢复操作：  

4、2、查看集群状态等待数据恢复完成  
```
# ceph status
  cluster:
    id: 15484ab5-ddb2-4a54-b9b3-ed8674bc5d05
    health: HEALTH_WARN
            Reduced data availability: 4 pgs inactive
            Degraded data redundancy: 21/186 objects degraded (11.290%),
8 pgs degraded, 28 pgs undersized
            application not enabled on 1 pool(s)
  services:
    mon: 3 daemons, quorum c720176,c720177,c720178
    mgr: c720176(active), standbys: c720178, c720177
    mds: cephfs-1/1/1 up {0=c720178=up:active}, 2 up:standby
    osd: 9 osds: 8 up, 8 in
...
```  

5、从 Ceph crush map 中删除故障磁盘 OSD  
``` # ceph osd crush rm osd.3 ```  

6、删除 OSD 的 Ceph 身份验证密钥  
``` # ceph auth del osd.3 ```  

7、从集群中删除 OSD  
``` # ceph osd rm osd.3 ```  

- 由于其中一个OSD不可用，因此群集运行状况不正常，群集将执行恢复。恢复操作完成后，群集将获得 HEALTH_OK ：  
```
# ceph -s
# ceph osd stat
```  
