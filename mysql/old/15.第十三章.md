# NoSQL--MongoDB基础运维

## 第一章：逻辑结构

```
Mongodb 逻辑结构             			 MySQL逻辑结构
库database								    库
集合（collection）							  表
文档（document）						  	 数据行

	
zabbix日志级别，改为debug模式，日志剧增
mysql服务器负载特别大
openstack部署时需要配置环境变量
k8s 一个etcd节点 意外情况down机，恢复的时候显示unheathy状态，怎么都不管事，最后把他数据目录删除提出节点，
docker发布新版本镜像推不上去
当时用mongdb的时候，创建个远程连接业务用户，但是业务怎么都连不上mongdb，查用户也有，但就是连不上，最后查资料，发现有验证库这一说，最后又加入验证库库名才登上去。
pv 200多万将近300万
uv 10万左右
ip 5000

rabbitmq  四种工作模式：基本主备模式，主节点提供读写，备节点不提供服务，主节点挂了就切换，备升主，用keepalive做虚拟vip漂移。
		远程模式：可以实现双活，用跨地域的形式进行互联。
		镜像模式: 可以保证数据100%不丢失，一般三个节点，主节点把数据同步到其他节点，有点类似数据库MHA
		多活模式：就是多个远程模式。
rabbitmq可以扮演生产者，消费者，以及代理方。
rabbitmq核心组件：连接管理器，信道，交换器，队列，路由键，绑定键
rabbitmq如何保证数据不丢失：消息持久化，ACK确认机制，设置集群镜像模式，消息补偿机制

redis完全基于内存，大部分都是纯粹的内存操作，非常迅速
redis五种数据类型：string  hash  list  set  Zset
redis高可用方案： 普通的主从，但是没有故障恢复功能。
				哨兵模式，哨兵集群每过多少秒通过ping来检测redis的集群状态，如果有节点客观下线了，就会选出新的主节点，剩下的节点指向新的节点来进行数据复制。
			
			
es监控 ：通过GET _cluster/health?pretty=true 来实现监控
```

## 第二章：安装部署

**安装前优化**

```
（1）redhat或centos6.2以上系统
（2）系统开发包完整
（3）ip地址和hosts文件解析正常
（4）iptables防火墙&SElinux关闭
（5）关闭大页内存机制
########################################################################
root用户下
在vi /etc/rc.local最后添加如下代码
if test -f /sys/kernel/mm/transparent_hugepage/enabled; then
  echo never > /sys/kernel/mm/transparent_hugepage/enabled
fi
if test -f /sys/kernel/mm/transparent_hugepage/defrag; then
   echo never > /sys/kernel/mm/transparent_hugepage/defrag
fi
		
cat  /sys/kernel/mm/transparent_hugepage/enabled		
cat /sys/kernel/mm/transparent_hugepage/defrag	
其他系统关闭参照官方文档：	

https://docs.mongodb.com/manual/tutorial/transparent-huge-pages/
---------------
为什么要关闭？
Transparent Huge Pages (THP) is a Linux memory management system 
that reduces the overhead of Translation Lookaside Buffer (TLB) 
lookups on machines with large amounts of memory by using larger memory pages.
However, database workloads often perform poorly with THP, 
because they tend to have sparse rather than contiguous memory access patterns. 
You should disable THP on Linux machines to ensure best performance with MongoDB.
############################################################################	

```

**mongodb安装**

```sh
## 创建所需用户和组
useradd mongod
passwd mongod

## 创建mongodb所需目录结构
mkdir -p /mongodb/conf
mkdir -p /mongodb/log
mkdir -p /mongodb/data

## 上传并解压软件到指定位置
[root@db01 opt]# tar xf mongodb-linux-x86_64-rhel70-4.2.8.tgz 
[root@db01 opt]# ln -s /opt/mongodb-linux-x86_64-rhel70-4.2.8 /usr/local/mongodb

## 设置目录结构权限
chown -R mongod:mongod /mongodb

## 设置用户环境变量
su - mongod
vi .bash_profile
export PATH=/usr/local/mongodb/bin:$PATH
source .bash_profile


## 启动mongodb
mongod --dbpath=/mongodb/data --logpath=/mongodb/log/mongodb.log --port=27017 --logappend --fork 

##  登录mongod
[mongod@server2 ~]$ mongo
```

**使用配置文件启动方式**

```sh
YAML模式

NOTE：
YAML does not support tab characters for indentation: use spaces instead.

--系统日志有关  
systemLog:
   destination: file        
   path: "/mongodb/log/mongodb.log"    --日志位置
   logAppend: true					   --日志以追加模式记录
  
--数据存储有关   
storage:
   journal:
      enabled: true
   dbPath: "/mongodb/data"            --数据路径的位置

-- 进程控制  
processManagement:
   fork: true                         --后台守护进程
   pidFilePath: <string>			  --pid文件的位置，一般不用配置，可以去掉这行，自动生成到data中
    
--网络配置有关   
net:			
   bindIp: <ip>                       -- 监听地址
   port: <port>						  -- 端口号,默认不配置端口号，是27017
   
-- 安全验证有关配置      
security:
  authorization: enabled              --是否打开用户名密码验证
  
------------------以下是复制集与分片集群有关----------------------  

replication:
 oplogSizeMB: <NUM>
 replSetName: "<REPSETNAME>"
 secondaryIndexPrefetch: "all"
 
sharding:
   clusterRole: <string>
   archiveMovedChunks: <boolean>
      
---for mongos only
replication:
   localPingThresholdMs: <int>

sharding:
   configDB: <string>
---
-------------------------------------------------------------
YAML例子
cat >  /mongodb/conf/mongo.conf <<EOF
systemLog:
   destination: file
   path: "/mongodb/log/mongodb.log"
   logAppend: true
storage:
   journal:
      enabled: true
   dbPath: "/mongodb/data/"
processManagement:
   fork: true
net:
   port: 27017
   bindIp: 10.0.0.51,127.0.0.1
EOF

mongod -f /mongodb/conf/mongo.conf --shutdown
mongod -f /mongodb/conf/mongo.conf   
```

**mongodb 使用systemd管理**

```sh
[root@db01 ~]# cat > /etc/systemd/system/mongod.service <<EOF
[Unit]
Description=mongodb 
After=network.target remote-fs.target nss-lookup.target
[Service]
User=mongod
Type=forking
ExecStart=/usr/local/mongodb/bin/mongod --config /mongodb/conf/mongo.conf
ExecReload=/bin/kill -s HUP $MAINPID
ExecStop=/usr/local/mongodb/bin/mongod --config /mongodb/conf/mongo.conf --shutdown
PrivateTmp=true  
[Install]
WantedBy=multi-user.target
EOF

[root@db01 ~]# systemctl restart mongod
[root@db01 ~]# systemctl stop mongod
[root@db01 ~]# systemctl start mongod
```

## mongodb常用基本操作

**3.0  mongodb 默认存在的库**

```
test:登录时默认存在的库
管理MongoDB有关的系统库
admin库:系统预留库,MongoDB系统管理库
local库:本地预留库,存储关键日志
config库:MongoDB配置信息库

show databases/show dbs
show tables/show collections
use admin 
db/select database()
```
**命令种类**

```
**db 对象相关命令**
db.[TAB][TAB]
db.help()
db.oldboy.[TAB][TAB]
db.oldboy.help()
```
**rs 复制集有关(replication set):**

```
rs.[TAB][TAB]
rs.help()
```
**sh 分片集群(sharding cluster)**

```
sh.[TAB][TAB]
sh.help()
```



## 库的操作

```
> use test
>db.dropDatabase()   
{ "dropped" : "test", "ok" : 1 }
```
**集合的操作**

```
app> db.createCollection('a')
{ "ok" : 1 }
app> db.createCollection('b')
方法2：当插入一个文档的时候，一个集合就会自动创建。

use oldboy
db.test.insert({name:"zhangsan"})
db.stu.insert({id:101,name:"zhangsan",age:20,gender:"m"})
show tables;
db.stu.insert({id:102,name:"lisi"})
db.stu.insert({a:"b",c:"d"})
db.stu.insert({a:1,c:2})
```
**文档操作**

```
数据录入：
for(i=0;i<10000;i++){db.log.insert({"uid":i,"name":"mongodb","age":6,"date":new
Date()})}

查询数据行数：
> db.log.count()
全表查询：
> db.log.find()
每页显示50条记录：
> DBQuery.shellBatchSize=50; 
按照条件查询
> db.log.find({uid:999})
以标准的json格式显示数据
> db.log.find({uid:999}).pretty()
{
	"_id" : ObjectId("5cc516e60d13144c89dead33"),
	"uid" : 999,
	"name" : "mongodb",
	"age" : 6,
	"date" : ISODate("2019-04-28T02:58:46.109Z")
}

删除集合中所有记录
app> db.log.remove({}
```

## 查看集合存储信息

```sh
app> db.log.totalSize() //集合中索引+数据压缩存储之后的大小
```



## 用户及权限管理

**注意**

```sh
验证库: 建立用户时use到的库，在使用用户时，要加上验证库才能登陆。

对于管理员用户,必须在admin下创建.
1. 建用户时,use到的库,就是此用户的验证库
2. 登录时,必须明确指定验证库才能登录
3. 通常,管理员用的验证库是admin,普通用户的验证库一般是所管理的库设置为验证库
4. 如果直接登录到数据库,不进行use,默认的验证库是test,不是我们生产建议的.
5. 从3.6 版本开始，不添加bindIp参数，默认不让远程登录，只能本地管理员登录。
```

**用户创建语法**

```sh
use admin 
db.createUser
{
    user: "<name>",
    pwd: "<cleartext password>",
    roles: [
       { role: "<role>",
     db: "<database>" } | "<role>",
    ...
    ]
}

基本语法说明：
user:用户名
pwd:密码
roles:
    role:角色名
    db:作用对象	
role：root, readWrite,read   
验证数据库：
mongo -u oldboy -p 123 10.0.0.53/创建用户时进入的库
```

**用户管理例子**

```sh
创建超级管理员：管理所有数据库（必须use admin再去创建）
$ mongo
use admin
db.createUser(
{
    user: "root",
    pwd: "root123",
    roles: [ { role: "root", db: "admin" } ]
}
)
```

**验证用户是否创建**

```sh
db.auth('root','root123')
## 配置文件中，加入以下配置,能远程登录，并检测用户身份
security:
  authorization: enabled
## 重启mongodb
mongod -f /mongodb/conf/mongo.conf --shutdown 
mongod -f /mongodb/conf/mongo.conf 
## 登录验证
mongo -uroot -proot123  admin   #可能验不出来
mongo -uroot -proot123  10.0.0.51/admin

或者
mongo
use admin
db.auth('root','root123')
```

**查看用户:**

```sh
use admin
db.system.users.find().pretty()
```

**创建应用用户**

```sh
use oldboy
db.createUser(
	{
		user: "app01",
		pwd: "app01",
		roles: [ { role: "readWrite" , db: "oldboy" } ]
	}
)

mongo  -uapp01 -papp01 oldboy
```

**删除用户（root身份登录，use到验证库）**

```sh
删除用户
db.createUser({user: "app02",pwd: "app02",roles: [ { role: "readWrite" , db: "oldboy1" } ]})
mongo -uroot -proot123 10.0.0.53/admin
use oldboy1
db.dropUser("app02")
```

**用户管理注意事项**

```sh
1. 建用户要有验证库，管理员admin，普通用户是要管理的库
2. 登录时，注意验证库
mongo -uapp01 -papp01 10.0.0.51:27017/oldboy
3. 重点参数
net:
   port: 27017
   bindIp: 10.0.0.51,127.0.0.1
security:
   authorization: enabled
```

## MongoDB复制集RS（ReplicationSet）

**基本原理**

```sh
基本构成是1主2从的结构，自带互相监控投票机制（Raft（MongoDB）  Paxos（mysql MGR 用的是变种））
如果发生主库宕机，复制集内部会进行投票选举，选择一个新的主库替代原有主库对外提供服务。同时复制集会自动通知
客户端程序，主库已经发生切换了。应用就会连接到新的主库。
```

**配置详解**

```sh
### 6.2.1  规划
三个以上的mongodb节点（或多实例）

###  6.2.2 环境准备
### 多个端口：
28017、28018、28019、28020

### 多套目录：	
su - mongod	
mkdir -p /mongodb/28017/conf /mongodb/28017/data /mongodb/28017/log
mkdir -p /mongodb/28018/conf /mongodb/28018/data /mongodb/28018/log
mkdir -p /mongodb/28019/conf /mongodb/28019/data /mongodb/28019/log
mkdir -p /mongodb/28020/conf /mongodb/28020/data /mongodb/28020/log

### 多套配置文件		
/mongodb/28017/conf/mongod.conf
/mongodb/28018/conf/mongod.conf
/mongodb/28019/conf/mongod.conf
/mongodb/28020/conf/mongod.conf

### 配置文件内容
cat > /mongodb/28017/conf/mongod.conf <<EOF
systemLog:
  destination: file
  path: /mongodb/28017/log/mongodb.log
  logAppend: true
storage:
  journal:
    enabled: true
  dbPath: /mongodb/28017/data
  directoryPerDB: true
  #engine: wiredTiger
  wiredTiger:
    engineConfig:
      cacheSizeGB: 1
      directoryForIndexes: true
    collectionConfig:
      blockCompressor: zlib
    indexConfig:
      prefixCompression: true
processManagement:
  fork: true
net:
  bindIp: 10.0.0.51,127.0.0.1
  port: 28017
replication:
  oplogSizeMB: 2048
  replSetName: my_repl
EOF
		

\cp  /mongodb/28017/conf/mongod.conf  /mongodb/28018/conf/
\cp  /mongodb/28017/conf/mongod.conf  /mongodb/28019/conf/
\cp  /mongodb/28017/conf/mongod.conf  /mongodb/28020/conf/

sed 's#28017#28018#g' /mongodb/28018/conf/mongod.conf -i
sed 's#28017#28019#g' /mongodb/28019/conf/mongod.conf -i
sed 's#28017#28020#g' /mongodb/28020/conf/mongod.conf -i

### 启动多个实例备用
mongod -f /mongodb/28017/conf/mongod.conf
mongod -f /mongodb/28018/conf/mongod.conf
mongod -f /mongodb/28019/conf/mongod.conf
mongod -f /mongodb/28020/conf/mongod.conf
netstat -lnp|grep 280
```

**配置普通复制集**

```sh

#1主2从，从库普通从库
mongo --port 28017 admin
config = {_id: 'my_repl', members: [
                          {_id: 0, host: '10.0.0.51:28017'},
                          {_id: 1, host: '10.0.0.51:28018'},
                          {_id: 2, host: '10.0.0.51:28019'}]
          }

rs.initiate(config) 

查询复制集状态
rs.status();


## 6.4 1主1从1个arbiter
​```
mongo -port 28017 admin
config = {_id: 'my_repl', members: [
                          {_id: 0, host: '10.0.0.51:28017'},
                          {_id: 1, host: '10.0.0.51:28018'},
                          {_id: 2, host: '10.0.0.51:28019',"arbiterOnly":true}]
          }     

rs.initiate(config) 
```

 **复制集管理操作**

```sh
### 6.5.1 查看复制集状态
​```
rs.status();    //查看整体复制集状态
rs.isMaster(); // 查看当前是否是主节点
rs.conf();   //查看复制集配置信息

### 6.5.2 添加删除节点
rs.remove("ip:port"); // 删除一个节点
rs.add("ip:port"); // 新增从节点
rs.addArb("ip:port"); // 新增仲裁节点 ,就是啥也不干，只负责投票出主库的
例子：
添加 arbiter节点
1、连接到主节点
[mongod@db03 ~]$ mongo --port 28018 admin
2、添加仲裁节点
my_repl:PRIMARY> rs.addArb("10.0.0.53:28020")
3、查看节点状态
my_repl:PRIMARY> rs.isMaster()
{
	"hosts" : [
		"10.0.0.53:28017",
		"10.0.0.53:28018",
		"10.0.0.53:28019"
	],
	"arbiters" : [
		"10.0.0.53:28020"
	],

rs.remove("ip:port"); // 删除一个节点
例子：
my_repl:PRIMARY> rs.remove("10.0.0.53:28019");
{ "ok" : 1 }
my_repl:PRIMARY> rs.isMaster()
rs.add("ip:port"); // 新增从节点
例子：
my_repl:PRIMARY> rs.add("10.0.0.53:28019")
{ "ok" : 1 }
my_repl:PRIMARY> rs.isMaster()
```

**特殊从节点**

```sh
### 介绍：
arbiter节点：主要负责选主过程中的投票，但是不存储任何数据，也不提供任何服务
hidden节点：隐藏节点，不参与选主，也不对外提供服务。
delay节点：延时节点，数据落后于主库一段时间，因为数据是延时的，也不应该提供服务或参与选主，所以通常会配合hidden（隐藏）
一般情况下会将delay+hidden一起配置使用

### 配置延时节点（一般延时节点也配置成hidden）
cfg=rs.conf() 
cfg.members[3].priority=0
cfg.members[3].hidden=true
cfg.members[3].slaveDelay=120
rs.reconfig(cfg)    
#3为下表索引集合。就是第四个

取消以上配置
cfg=rs.conf() 

cfg.members[3].priority=1
cfg.members[3].hidden=false
cfg.members[3].slaveDelay=0
rs.reconfig(cfg)    


配置成功后，通过以下命令查询配置后的属性
rs.conf(); 
```

**副本集其他操作命令**

```sh
查看副本集的配置信息
admin> rs.conf()
查看副本集各成员的状态
admin> rs.status()
++++++++++++++++++++++++++++++++++++++++++++++++
--副本集角色切换（不要人为随便操作）
admin> rs.stepDown()
注：
admin> rs.freeze(300) //锁定从，使其不会转变成主库
freeze()和stepDown单位都是秒。
+++++++++++++++++++++++++++++++++++++++++++++
设置副本节点可读：在副本节点执行
admin> rs.slaveOk()
eg：
admin> use app
switched to db app
app> db.createCollection('a')
{ "ok" : 0, "errmsg" : "not master", "code" : 10107 }

查看副本节点（监控主从延时）
admin> rs.printSlaveReplicationInfo()
source: 192.168.1.22:27017
	syncedTo: Thu May 26 2016 10:28:56 GMT+0800 (CST)
	0 secs (0 hrs) behind the primary
```

## MongoDB Sharding Cluster 分片集群

**规划**

```sh
10个实例：38017-38026
（1）configserver:38018-38020
3台构成的复制集（1主两从，不支持arbiter）38018-38020（复制集名字configsvr）
（2）shard节点：
sh1：38021-23    （1主两从，其中一个节点为arbiter，复制集名字sh1）
sh2：38024-26    （1主两从，其中一个节点为arbiter，复制集名字sh2）
（3） mongos:
38017
```

**shard节点配置**

```sh
### 7.2.1 目录创建：
mkdir -p /mongodb/38021/conf  /mongodb/38021/log  /mongodb/38021/data
mkdir -p /mongodb/38022/conf  /mongodb/38022/log  /mongodb/38022/data
mkdir -p /mongodb/38023/conf  /mongodb/38023/log  /mongodb/38023/data
mkdir -p /mongodb/38024/conf  /mongodb/38024/log  /mongodb/38024/data
mkdir -p /mongodb/38025/conf  /mongodb/38025/log  /mongodb/38025/data
mkdir -p /mongodb/38026/conf  /mongodb/38026/log  /mongodb/38026/data
​```
### 7.2.2 修改配置文件：

### 第一组复制集搭建：21-23（1主 1从 1Arb）
cat >  /mongodb/38021/conf/mongodb.conf  <<EOF
systemLog:
  destination: file
  path: /mongodb/38021/log/mongodb.log   
  logAppend: true
storage:
  journal:
    enabled: true
  dbPath: /mongodb/38021/data
  directoryPerDB: true
  #engine: wiredTiger
  wiredTiger:
    engineConfig:
      cacheSizeGB: 1
      directoryForIndexes: true
    collectionConfig:
      blockCompressor: zlib
    indexConfig:
      prefixCompression: true
net:
  bindIp: 10.0.0.51,127.0.0.1
  port: 38021
replication:
  oplogSizeMB: 2048
  replSetName: sh1
sharding:
  clusterRole: shardsvr
processManagement: 
  fork: true
EOF
\cp  /mongodb/38021/conf/mongodb.conf  /mongodb/38022/conf/
\cp  /mongodb/38021/conf/mongodb.conf  /mongodb/38023/conf/

sed 's#38021#38022#g' /mongodb/38022/conf/mongodb.conf -i
sed 's#38021#38023#g' /mongodb/38023/conf/mongodb.conf -i

###  第二组节点：24-26(1主1从1Arb)
cat > /mongodb/38024/conf/mongodb.conf <<EOF
systemLog:
  destination: file
  path: /mongodb/38024/log/mongodb.log   
  logAppend: true
storage:
  journal:
    enabled: true
  dbPath: /mongodb/38024/data
  directoryPerDB: true
  wiredTiger:
    engineConfig:
      cacheSizeGB: 1
      directoryForIndexes: true
    collectionConfig:
      blockCompressor: zlib
    indexConfig:
      prefixCompression: true
net:
  bindIp: 10.0.0.51,127.0.0.1
  port: 38024
replication:
  oplogSizeMB: 2048
  replSetName: sh2
sharding:
  clusterRole: shardsvr
processManagement: 
  fork: true
EOF

\cp  /mongodb/38024/conf/mongodb.conf  /mongodb/38025/conf/
\cp  /mongodb/38024/conf/mongodb.conf  /mongodb/38026/conf/
sed 's#38024#38025#g' /mongodb/38025/conf/mongodb.conf -i
sed 's#38024#38026#g' /mongodb/38026/conf/mongodb.conf -i

### 7.2.3 启动所有节点，并搭建复制集
mongod -f  /mongodb/38021/conf/mongodb.conf 
mongod -f  /mongodb/38022/conf/mongodb.conf 
mongod -f  /mongodb/38023/conf/mongodb.conf 
mongod -f  /mongodb/38024/conf/mongodb.conf 
mongod -f  /mongodb/38025/conf/mongodb.conf 
mongod -f  /mongodb/38026/conf/mongodb.conf  
ps -ef |grep mongod

mongo --port 38021
use  admin
config = {_id: 'sh1', members: [
                          {_id: 0, host: '10.0.0.51:38021'},
                          {_id: 1, host: '10.0.0.51:38022'},
                          {_id: 2, host: '10.0.0.51:38023',"arbiterOnly":true}]
           }

rs.initiate(config)
  
 mongo --port 38024 
 use admin
config = {_id: 'sh2', members: [
                          {_id: 0, host: '10.0.0.51:38024'},
                          {_id: 1, host: '10.0.0.51:38025'},
                          {_id: 2, host: '10.0.0.51:38026',"arbiterOnly":true}]
           }
  
rs.initiate(config)
```

**config节点配置(PSS)**

```sh
### 7.3.1 目录创建
mkdir -p /mongodb/38018/conf  /mongodb/38018/log  /mongodb/38018/data
mkdir -p /mongodb/38019/conf  /mongodb/38019/log  /mongodb/38019/data
mkdir -p /mongodb/38020/conf  /mongodb/38020/log  /mongodb/38020/data

### 7.3.2修改配置文件：
cat > /mongodb/38018/conf/mongodb.conf <<EOF
systemLog:
  destination: file
  path: /mongodb/38018/log/mongodb.conf
  logAppend: true
storage:
  journal:
    enabled: true
  dbPath: /mongodb/38018/data
  directoryPerDB: true
  #engine: wiredTiger
  wiredTiger:
    engineConfig:
      cacheSizeGB: 1
      directoryForIndexes: true
    collectionConfig:
      blockCompressor: zlib
    indexConfig:
      prefixCompression: true
net:
  bindIp: 10.0.0.51,127.0.0.1
  port: 38018
replication:
  oplogSizeMB: 2048
  replSetName: configReplSet
sharding:
  clusterRole: configsvr
processManagement: 
  fork: true
EOF

\cp /mongodb/38018/conf/mongodb.conf /mongodb/38019/conf/
\cp /mongodb/38018/conf/mongodb.conf /mongodb/38020/conf/
sed 's#38018#38019#g' /mongodb/38019/conf/mongodb.conf -i
sed 's#38018#38020#g' /mongodb/38020/conf/mongodb.conf -i

### 7.3.3启动节点，并配置复制集
mongod -f /mongodb/38018/conf/mongodb.conf 
mongod -f /mongodb/38019/conf/mongodb.conf 
mongod -f /mongodb/38020/conf/mongodb.conf 

mongo --port 38018
use  admin
 config = {_id: 'configReplSet', members: [
                          {_id: 0, host: '10.0.0.51:38018'},
                          {_id: 1, host: '10.0.0.51:38019'},
                          {_id: 2, host: '10.0.0.51:38020'}]
           }
rs.initiate(config)  
  
注：configserver 可以是一个节点，官方建议复制集。configserver不能有arbiter。
新版本中，要求必须是复制集。
注：mongodb 3.4之后，虽然要求config server为replica set，但是不支持arbiter
```

**mongos节点配置**

```sh
### 7.4.1创建目录：
mkdir -p /mongodb/38017/conf  /mongodb/38017/log 

###  7.4.2配置文件：
	cat > /mongodb/38017/conf/mongos.conf <<EOF
	systemLog:
	  destination: file
	  path: /mongodb/38017/log/mongos.log
	  logAppend: true
	net:
	  bindIp: 10.0.0.51,127.0.0.1
	  port: 38017
	sharding:
	  configDB: configReplSet/10.0.0.51:38018,10.0.0.51:38019,10.0.0.51:38020
	processManagement: 
	  fork: true
	EOF
      
### 7.4.3启动mongos
 mongos -f /mongodb/38017/conf/mongos.conf 
```

**分片集群添加节点**

```sh
连接到其中一个mongos（10.0.0.51），做以下配置
（1）连接到mongs的admin数据库
# su - mongod
$ mongo 10.0.0.51:38017/admin
（2）添加分片
db.runCommand( { addshard : "sh1/10.0.0.51:38021,10.0.0.51:38022,10.0.0.51:38023",name:"shard1"} )
db.runCommand( { addshard : "sh2/10.0.0.51:38024,10.0.0.51:38025,10.0.0.51:38026",name:"shard2"} )
（3）列出分片
mongos> db.runCommand( { listshards : 1 } )
（4）整体状态查看
mongos> sh.status();
```

**使用分片集群**

```sh
###  7.6.1 RANGE分片配置及测试
### RANG自动分片
mongo --port 38017 admin
use admin 
db.runCommand( { enablesharding : "autoshard" } )

use autoshard
db.autotab.ensureIndex( { id: 1 } )

use admin
db.runCommand( { shardcollection : "autoshard.autotab",key : {id: 1} } )


use autoshard
for(i=1;i<100000;i++){ db.autotab.insert({"id":i,"name":"shenzheng","age":70,"date":new Date()}); }
db.autotab.stats()


### zone方式进行range手工定制分片

mongo --port 38017 admin    #mogons节点
use zonedb
db.vast.ensureIndex( {order_id: 1 } )


use admin
db.runCommand( { enablesharding : "zonedb" } )
sh.shardCollection("zonedb.vast", {order_id: 1});


sh.addShardTag("shard1", "shard00")
sh.addShardTag("shard2", "shard01")


sh.addTagRange( 
"zonedb.vast", 
{  "order_id" : MinKey },
{  "order_id" : 500 },"shard00" )

sh.addTagRange( 
"zonedb.vast",
{"order_id" : 501 },
{"order_id" : MaxKey},"shard01" )


use zonedb
for(i=1;i<1000;i++){ db.vast.insert({"order_id":i,"name":"shenzheng","age":70,"date":new Date()}); }


db.vast.getShardDistribution()

### 7.6.2 Hash分片例子：

对oldboy库下的vast大表进行hash

mongo --port 38017 admin
use admin
db.runCommand( { enablesharding : "oldboy" } )

use oldboy
db.vast.ensureIndex( { id: "hashed" } )

use admin
sh.shardCollection( "oldboy.vast", { id: "hashed" } )

use oldboy
for(i=1;i<1000;i++){ db.vast.insert({"id":i,"name":"shenzheng","age":70,"date":new Date()}); }
```

**分片集群的查询及管理**

```sh
### 7.7.1 判断是否Shard集群
admin> db.runCommand({ isdbgrid : 1})

### 7.7.2 列出所有分片信息
admin> db.runCommand({ listshards : 1})

### 7.7.3 列出开启分片的数据库
admin> use config
config> db.databases.find( { "partitioned": true } )
或者：
config> db.databases.find() //列出所有数据库分片情况

### 7.7.4 查看分片的片键
config> db.collections.find().pretty()
{
	"_id" : "test.vast",
	"lastmodEpoch" : ObjectId("58a599f19c898bbfb818b63c"),
	"lastmod" : ISODate("1970-02-19T17:02:47.296Z"),
	"dropped" : false,
	"key" : {
		"id" : 1
	},
	"unique" : false
}

### 7.7.5 查看分片的详细信息
admin> sh.status()

### 7.7.6 删除分片节点（谨慎）
（1）确认blance是否在工作
sh.getBalancerState()
（2）删除shard2节点(谨慎)
mongos> db.runCommand( { removeShard: "shard2" } )
注意：删除操作一定会立即触发blancer。
```

**balancer操作**

```sh
### 7.8.1 介绍
mongos的一个重要功能，自动巡查所有shard节点上的chunk的情况，自动做chunk迁移。
什么时候工作？
1、自动运行，会检测系统不繁忙的时候做迁移
2、在做节点删除的时候，立即开始迁移工作
3、balancer只能在预设定的时间窗口内运行

有需要时可以关闭和开启blancer（备份的时候）
mongos> sh.stopBalancer()
mongos> sh.startBalancer()

### 7.8.2 自定义 自动平衡进行的时间段
https://docs.mongodb.com/manual/tutorial/manage-sharded-cluster-balancer/#schedule-the-balancing-window
// connect to mongos
#配置balancer运行时间段
use config
sh.setBalancerState( true )
db.settings.update({ _id : "balancer" }, { $set : { activeWindow : { start : "3:00", stop : "5:00" } } }, true )

sh.getBalancerWindow()
sh.status()

关于集合的balancer（了解下）
关闭某个集合的balance
sh.disableBalancing("students.grades")
打开某个集合的balancer
sh.enableBalancing("students.grades")
确定某个集合的balance是开启或者关闭
db.getSiblingDB("config").collections.findOne({_id : "students.grades"}).noBalance;
```

## 备份恢复 

**mongoexport** 

```sh
#  单表备份至json格式
mongoexport -uroot -proot123 --port 27017 --authenticationDatabase admin -d oldboy -c log -o /mongodb/log.json  备份oldboy库下的log表

注：备份文件的名字可以自定义，默认导出了JSON格式的数据。

# 单表备份至csv格式
如果我们需要导出CSV格式的数据，则需要使用----type=csv参数：-f指定列名

 mongoexport -uroot -proot123 --port 27017 --authenticationDatabase admin -d oldboy -c log --type=csv -f uid,name,age,date  -o /mongodb/log.csv

```

**mongoimport**

```sh
# 恢复json格式表数据到log1
mongoimport -uroot -proot123 --port 27017 --authenticationDatabase admin -d oldboy -c log1 /mongodb/log.json

# 恢复csv格式的文件到log2
（1）csv格式的文件头行，有列名字
mongoimport   -uroot -proot123 --port 27017 --authenticationDatabase admin   -d oldboy -c log2 --type=csv --headerline --file  /mongodb/log.csv

（2）csv格式的文件头行，没有列名字
mongoimport   -uroot -proot123 --port 27017 --authenticationDatabase admin   -d oldboy -c log3 --type=csv -f id,name,age,date --file  /mongodb/log.csv

--headerline:指明第一行是列名，不需要导入。
```

**MySQL ---> Mongodb迁移** 

```sh
a. 导出MySQL数据为CSV格式 

select * from test.t100w  limit 100  into outfile '/tmp/t100w.csv' fields terminated by ',';

b. 导入MongoDB 
[mongod@db01 mongodb]$ mongoimport   -uroot -proot123 --port 27017 --authenticationDatabase admin  -d test -c t100w --type=csv  -f id,num,k1,k2,dt  --file /mongodb/t100w.csv
```

**mongodump** 

```sh
# 全库备份
mkdir /mongodb/backup
mongodump  -uroot -proot123 --port 27017 --authenticationDatabase admin -o /mongodb/backup

# 备份test库
mongodump   -uroot -proot123 --port 27017 --authenticationDatabase admin -d test -o /mongodb/backup/


# 备份oldboy库下的log集合
mongodump   -uroot -proot123 --port 27017 --authenticationDatabase admin -d oldboy -c log -o /mongodb/backup/


# 压缩备份

mongodump   -uroot -proot123 --port 27017 --authenticationDatabase admin -d test -o /mongodb/backup/ --gzip
```

**mongorestore**

```sh
[mongod@db01 ~]$ mongorestore   -uroot -proot123 --port 27017 --authenticationDatabase admin  /mongodb/backup/ --gzip

# 全库恢复 
[mongod@db01 ~]$ mongorestore   -uroot -proot123 --port 27017 --authenticationDatabase admin  /mongodb/backup/ --gzip --drop   #drop参数慎用

# 恢复test库
[mongod@db01 ~]$ mongorestore   -uroot -proot123 --port 27017 --authenticationDatabase admin  -d oldguo /mongodb/backup/test  --gzip --drop 

恢复test库下的t100w集合

[mongod@db01 ~]$ mongorestore   -uroot -proot123 --port 27017 --authenticationDatabase admin  -d oldguo  -c t1  /mongodb/backup/test/t100w.bson.gz  --gzip 


drop表示恢复的时候把之前的集合drop掉(危险)

$ mongorestore  -uroot -proot123 --port 27017 --authenticationDatabase admin -d oldboy --drop  

```

**mongodump和mongorestore高级企业应用（--oplog）**

```sh
8.6.1 oplog介绍
注意：这是replica set 模式专用
--oplog
 use oplog for taking a point-in-time snapshot
 
在replica set中oplog是一个定容集合（capped collection），它的默认大小是磁盘空间的5%（可以通过--oplogSizeMB参数修改）.
位于local库的db.oplog.rs，有兴趣可以看看里面到底有些什么内容。
其中记录的是整个mongod实例一段时间内数据库的所有变更（插入/更新/删除）操作。
当空间用完时新记录自动覆盖最老的记录。
其覆盖范围被称作oplog时间窗口。需要注意的是，因为oplog是一个定容集合，
所以时间窗口能覆盖的范围会因为你单位时间内的更新次数不同而变化。
想要查看当前的oplog时间窗口预计值，可以使用以下命令：

 mongod -f /mongodb/28017/conf/mongod.conf 
 mongod -f /mongodb/28018/conf/mongod.conf 
 mongod -f /mongodb/28019/conf/mongod.conf 
 mongod -f /mongodb/28020/conf/mongod.conf 
 
 
 use local 
 db.oplog.rs.find().pretty()
"ts" : Timestamp(1553597844, 1),
"op" : "n"
"o"  :

"i": insert
"u": update
"d": delete
"c": db cmd

test:PRIMARY> rs.printReplicationInfo()
configured oplog size:   1561.5615234375MB <--集合大小
log length start to end: 423849secs (117.74hrs) <--预计窗口覆盖时间
oplog first event time:  Wed Sep 09 2015 17:39:50 GMT+0800 (CST)
oplog last event time:   Mon Sep 14 2015 15:23:59 GMT+0800 (CST)
now:                     Mon Sep 14 2015 16:37:30 GMT+0800 (CST)



8.6.2 oplog企业级应用
（1）实现热备，在备份时使用--oplog选项

（2）准备测试数据
[mongod@db01 conf]$ mongo --port 28018

use oldboy
for(var i = 1 ;i < 100; i++) {
    db.foo.insert({a:i});
}

my_repl:PRIMARY> db.oplog.rs.find({"op":"i"}).pretty()

oplog 配合mongodump实现热备
mongodump --port 28018 --oplog -o /mongodb/backup
作用介绍：--oplog 会记录备份过程中的数据变化。会以oplog.bson保存下来
恢复
mongorestore  --port 28017 --oplogReplay /mongodb/bak --drop
```

**oplog高级应用**

```sh
背景：每天11点全备，oplog恢复窗口为48小时
某天，上午10点world.city 业务表被误删除。
恢复思路：
    0、停应用
    2、找测试库
    3、恢复昨天晚上全备
    4、截取全备之后到world.city误删除时间点的oplog，并恢复到测试库
    5、将误删除表导出，恢复到生产库

恢复步骤：
模拟故障环境：

1、全备数据库
模拟原始数据

mongo --port 28017
use test
for(var i = 1 ;i < 100; i++) {
    db.a.insert({a: i});
}

全备:
rm -rf /mongodb/backup/*
mongodump --port 28017 --oplog -o /mongodb/backup

--oplog功能:在备份同时,将备份过程中产生的日志进行备份
文件必须存放在/mongodb/backup下,自动命令为oplog.bson

再次模拟数据
db.b.insert({id:1})
db.c.insert({id:2})


2、上午10点：删除wo库下的ci表
10:00时刻,误删除


3、备份现有的oplog.rs表
mongodump --port 28017 -d local -c oplog.rs  -o /mongodb/bak

4、截取oplog并恢复到drop之前的位置
更合理的方法：登陆到原数据库
[mongod@db03 local]$	
my_repl:PRIMARY> use local
db.oplog.rs.find({op:"c"}).pretty();

{
	"ts" : Timestamp(1606212278, 1),
	"t" : NumberLong(3),
	"h" : NumberLong(0),
	"v" : 2,
	"op" : "c",
	"ns" : "test.$cmd",
	"ui" : UUID("091af5ca-20c2-4ea4-a015-7b42de975220"),
	"o2" : {
		"numRecords" : 1
	},
	"wall" : ISODate("2020-11-24T10:04:38.310Z"),
	"o" : {
		"drop" : "b"
	}
}

获取到oplog误删除时间点位置:
	"ts" : Timestamp(1606212278, 1),
```

**恢复备份+应用oplog**

```sh
[mongod@db01 backup]$ cp /mongodb/bak/local/oplog.rs.bson ./oplog.bson 
mongorestore --port 28017  --oplogReplay --oplogLimit "1606212278:1"  --drop   /mongodb/backup/    #意思是恢复到那个号码之前
```

